###############
Setup
###############
#######
# HIVE
#######

Logging initialized using configuration in jar:file:/home/sandeep/tools/hive/0.13.1/lib/hive-common-0.13.1.jar!/hive-log4j.properties
drop table if exists page_view
OK
Time taken: 0.538 seconds

drop table if exists apachelog
OK
Time taken: 0.013 seconds

drop table if exists apachelog_text
OK
Time taken: 0.014 seconds

drop table if exists apachelog_orc
OK
Time taken: 0.014 seconds

drop table if exists strange_string
OK
Time taken: 0.014 seconds

drop table if exists india_pow_gen
OK
Time taken: 0.015 seconds

drop table if exists nodes
OK
Time taken: 1.327 seconds

drop table if exists nodes_string
OK
Time taken: 0.132 seconds

drop table if exists edges
OK
Time taken: 0.12 seconds

drop table if exists edges_string
OK
Time taken: 0.119 seconds

drop table if exists components
OK
Time taken: 0.114 seconds


DROP FUNCTION IF EXISTS rowWithHeader
OK
Time taken: 0.482 seconds

DROP FUNCTION IF EXISTS components
OK
Time taken: 0.008 seconds

DROP FUNCTION IF EXISTS components_wqupc
OK
Time taken: 0.007 seconds
[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building connected_components 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.4.1:clean (default-clean) @ connected_components ---
[INFO] Deleting /home/sandeep/projects/big_data/udaf/target
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building connected_components 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ connected_components >>>
[WARNING] The artifact org.apache.commons:commons-io:jar:1.3.2 has been relocated to commons-io:commons-io:jar:1.3.2
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ connected_components ---
[debug] execute contextualize
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/sandeep/projects/big_data/udaf/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ connected_components ---
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 2 source files to /home/sandeep/projects/big_data/udaf/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ connected_components ---
[debug] execute contextualize
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/sandeep/projects/big_data/udaf/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:testCompile (default-testCompile) @ connected_components ---
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 1 source file to /home/sandeep/projects/big_data/udaf/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.8:test (default-test) @ connected_components ---
[INFO] Surefire report directory: /home/sandeep/projects/big_data/udaf/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running me.tingri.hive.udaf.ConnectedComponentsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.058 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:2.3.2:jar (default-jar) @ connected_components ---
[INFO] Building jar: /home/sandeep/projects/big_data/udaf/target/connected_components-0.1.jar
[INFO] 
[INFO] <<< maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ connected_components <<<
[INFO] 
[INFO] --- maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ connected_components ---
[INFO] Building jar: /home/sandeep/projects/big_data/udaf/target/connected_components-0.1-jar-with-dependencies.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 4.377s
[INFO] Finished at: Tue Jan 20 19:32:47 EST 2015
[INFO] Final Memory: 42M/348M
[INFO] ------------------------------------------------------------------------

Logging initialized using configuration in jar:file:/home/sandeep/tools/hive/0.13.1/lib/hive-common-0.13.1.jar!/hive-log4j.properties
ADD JAR ${env:PROJECT_HOME}/udaf/target/connected_components-0.1-jar-with-dependencies.jar
Added /home/sandeep/projects/big_data/udaf/target/connected_components-0.1-jar-with-dependencies.jar to class path
Added resource: /home/sandeep/projects/big_data/udaf/target/connected_components-0.1-jar-with-dependencies.jar


create temporary function components as 'me.tingri.hive.udaf.ConnectedComponents'
OK
Time taken: 0.635 seconds

create temporary function components_wqupc as 'me.tingri.hive.udaf.ConnectedComponentsWQUPC'
OK
Time taken: 0.009 seconds


CREATE TABLE edges_string(node1 STRING, node2 STRING)
  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
OK
Time taken: 0.408 seconds


CREATE TABLE nodes_string(node STRING)
  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
OK
Time taken: 0.036 seconds


CREATE TABLE edges(id1 INT, id2 INT)
  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
OK
Time taken: 0.039 seconds


CREATE TABLE nodes(id INT, node STRING)
  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
OK
Time taken: 0.037 seconds


CREATE TABLE components(root_array ARRAY<INT>)
  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
OK
Time taken: 0.034 seconds


LOAD DATA LOCAL INPATH '${env:DATA_SETS_FOLDER}/edges.csv' OVERWRITE INTO TABLE edges_string
Copying data from file:/home/sandeep/projects/big_data/datasets/edges.csv
Copying file: file:/home/sandeep/projects/big_data/datasets/edges.csv
Loading data to table default.edges_string
rmr: DEPRECATED: Please use 'rm -r' instead.
Deleted hdfs://localhost:9000/user/hive/warehouse/edges_string
Table default.edges_string stats: [numFiles=1, numRows=0, totalSize=50, rawDataSize=0]
OK
Time taken: 1.169 seconds


SELECT components(node1, node2) from edges_string
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1421796569267_0025)

Map 1: -/-	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Map 1: 1/1	Reducer 2: 0/1	
Map 1: 1/1	Reducer 2: 1/1	
Status: Finished successfully
OK
{"N9":["N20","N4","N9"],"N5":["N1","N3","N5","N2","N6"],"N6":["N1","N3","N5","N2","N6"],"N7":["N7","N8"],"N8":["N7","N8"],"N1":["N1","N3","N5","N2","N6"],"N2":["N1","N3","N5","N2","N6"],"N3":["N1","N3","N5","N2","N6"],"N20":["N20","N4","N9"],"N4":["N20","N4","N9"],"N10":["N10","N11"],"N11":["N10","N11"]}
Time taken: 9.034 seconds, Fetched: 1 row(s)


INSERT  into table nodes_string
select distinct node FROM
  (
    select node1 as node from edges_string
    UNION ALL select node2 as node from edges_string
  ) new_table
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1421796569267_0025)

Map 1: -/-	Map 4: -/-	Reducer 3: 0/1	
Map 1: 0/1	Map 4: 0/1	Reducer 3: 0/1	
Map 1: 1/1	Map 4: 0/1	Reducer 3: 0/1	
Map 1: 1/1	Map 4: 1/1	Reducer 3: 0/1	
Map 1: 1/1	Map 4: 1/1	Reducer 3: 1/1	
Status: Finished successfully
Loading data to table default.nodes_string
Table default.nodes_string stats: [numFiles=1, numRows=12, totalSize=39, rawDataSize=27]
OK
Time taken: 2.005 seconds


Insert into table nodes
SELECT  row_number() over() as id, node
from nodes_string
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1421796569267_0025)

Map 1: -/-	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Map 1: 1/1	Reducer 2: 0/1	
Map 1: 1/1	Reducer 2: 1/1	
Status: Finished successfully
Loading data to table default.nodes
Table default.nodes stats: [numFiles=1, numRows=12, totalSize=66, rawDataSize=54]
OK
Time taken: 1.429 seconds


Insert into table edges
select id1, id as id2
from ( select  id as id1, node2
       from edges_string, nodes
       where node1 = node ) new_table, nodes
where node2 = node
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1421796569267_0025)

Map 1: -/-	Map 2: -/-	Map 3: -/-	
Map 1: 0/1	Map 2: 0/1	Map 3: 0/1	
Map 1: 0/1	Map 2: 0/1	Map 3: 1/1	
Map 1: 1/1	Map 2: 0/1	Map 3: 1/1	
Map 1: 1/1	Map 2: 1/1	Map 3: 1/1	
Status: Finished successfully
Loading data to table default.edges
Table default.edges stats: [numFiles=1, numRows=8, totalSize=37, rawDataSize=29]
OK
Time taken: 1.472 seconds


insert into table components
SELECT components_wqupc(100, id1, id2) as cluster
from edges
Number of edges 100PARTIAL1
Total jobs = 1
Launching Job 1 out of 1


Status: Running (application id: application_1421796569267_0025)

Map 1: -/-	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Map 1: 0/1	Reducer 2: 0/1	
Status: Failed
Vertex failed, vertexName=Map 1, vertexId=vertex_1421796569267_0025_5_01, diagnostics=[Task failed, taskId=task_1421796569267_0025_5_01_000000, diagnostics=[AttemptID:attempt_1421796569267_0025_5_01_000000_0 Info:Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:195)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:161)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:164)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:307)
	at org.apache.hadoop.mapred.YarnTezDagChild$5.run(YarnTezDagChild.java:562)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)
	at org.apache.hadoop.mapred.YarnTezDagChild.main(YarnTezDagChild.java:551)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:550)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:183)
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ArrayIndexOutOfBoundsException: 100
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:808)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:540)
	... 9 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 100
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.addNodeIfNotExists(ConnectedComponentsWQUPC.java:212)
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.iterate(ConnectedComponentsWQUPC.java:95)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.aggregate(GenericUDAFEvaluator.java:183)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.updateAggregations(GroupByOperator.java:641)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:838)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processKey(GroupByOperator.java:735)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:803)
	... 15 more

Container released by application, AttemptID:attempt_1421796569267_0025_5_01_000000_1 Info:Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:195)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:161)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:164)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:307)
	at org.apache.hadoop.mapred.YarnTezDagChild$5.run(YarnTezDagChild.java:562)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)
	at org.apache.hadoop.mapred.YarnTezDagChild.main(YarnTezDagChild.java:551)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:550)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:183)
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ArrayIndexOutOfBoundsException: 100
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:808)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:540)
	... 9 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 100
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.addNodeIfNotExists(ConnectedComponentsWQUPC.java:212)
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.iterate(ConnectedComponentsWQUPC.java:95)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.aggregate(GenericUDAFEvaluator.java:183)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.updateAggregations(GroupByOperator.java:641)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:838)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processKey(GroupByOperator.java:735)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:803)
	... 15 more

Container released by application, AttemptID:attempt_1421796569267_0025_5_01_000000_2 Info:Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:195)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:161)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:164)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:307)
	at org.apache.hadoop.mapred.YarnTezDagChild$5.run(YarnTezDagChild.java:562)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)
	at org.apache.hadoop.mapred.YarnTezDagChild.main(YarnTezDagChild.java:551)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:550)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:183)
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ArrayIndexOutOfBoundsException: 100
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:808)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:540)
	... 9 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 100
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.addNodeIfNotExists(ConnectedComponentsWQUPC.java:212)
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.iterate(ConnectedComponentsWQUPC.java:95)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.aggregate(GenericUDAFEvaluator.java:183)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.updateAggregations(GroupByOperator.java:641)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:838)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processKey(GroupByOperator.java:735)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:803)
	... 15 more

Container released by application, AttemptID:attempt_1421796569267_0025_5_01_000000_3 Info:Error: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:195)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:161)
	at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:164)
	at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:307)
	at org.apache.hadoop.mapred.YarnTezDagChild$5.run(YarnTezDagChild.java:562)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)
	at org.apache.hadoop.mapred.YarnTezDagChild.main(YarnTezDagChild.java:551)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {"id1":3,"id2":2}
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:550)
	at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.processRow(MapRecordProcessor.java:183)
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ArrayIndexOutOfBoundsException: 100
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:808)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793)
	at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:540)
	... 9 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 100
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.addNodeIfNotExists(ConnectedComponentsWQUPC.java:212)
	at me.tingri.hive.udaf.ConnectedComponentsWQUPC$CCEvaluator.iterate(ConnectedComponentsWQUPC.java:95)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.aggregate(GenericUDAFEvaluator.java:183)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.updateAggregations(GroupByOperator.java:641)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:838)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processKey(GroupByOperator.java:735)
	at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:803)
	... 15 more
], Vertex failed as one or more tasks failed. failedTasks:1]
Vertex killed, vertexName=Reducer 2, vertexId=vertex_1421796569267_0025_5_00, diagnostics=[Vertex received Kill while in RUNNING state., Vertex killed as other vertex failed. failedTasks:0]
DAG failed due to vertex failure. failedVertices:1 killedVertices:1
FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask

Logging initialized using configuration in jar:file:/home/sandeep/tools/hive/0.13.1/lib/hive-common-0.13.1.jar!/hive-log4j.properties
hive> exit
    > ;
