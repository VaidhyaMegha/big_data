###############
Setup
###############
14/09/07 06:58:25 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = sandeep-Latitude-6430U/127.0.1.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.4.1
STARTUP_MSG:   classpath = /home/sandeep/tools/hadoop/2.4.1/etc/hadoop:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/hadoop-auth-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/xz-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/junit-4.8.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/hadoop-annotations-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/activation-1.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/asm-3.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/lib/jettison-1.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/hadoop-common-2.4.1-tests.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/hadoop-common-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/common/hadoop-nfs-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/hadoop-hdfs-2.4.1-tests.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/hdfs/hadoop-hdfs-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/zookeeper-3.4.5.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-api-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-client-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-common-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-server-common-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1-tests.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.4.1.jar:/home/sandeep/tools/hadoop/2.4.1/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/common -r 1604318; compiled by 'jenkins' on 2014-06-21T05:43Z
STARTUP_MSG:   java = 1.7.0_65
************************************************************/
14/09/07 06:58:25 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
14/09/07 06:58:25 INFO namenode.NameNode: createNameNode [-format]
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/09/07 06:58:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: CID-cdf0896c-eedb-4c7d-be6b-321f9026f738
14/09/07 06:58:26 INFO namenode.FSNamesystem: fsLock is fair:true
14/09/07 06:58:26 INFO namenode.HostFileManager: read includes:
HostSet(
)
14/09/07 06:58:26 INFO namenode.HostFileManager: read excludes:
HostSet(
)
14/09/07 06:58:26 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
14/09/07 06:58:26 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
14/09/07 06:58:26 INFO util.GSet: Computing capacity for map BlocksMap
14/09/07 06:58:26 INFO util.GSet: VM type       = 64-bit
14/09/07 06:58:26 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB
14/09/07 06:58:26 INFO util.GSet: capacity      = 2^21 = 2097152 entries
14/09/07 06:58:26 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
14/09/07 06:58:26 INFO blockmanagement.BlockManager: defaultReplication         = 1
14/09/07 06:58:26 INFO blockmanagement.BlockManager: maxReplication             = 512
14/09/07 06:58:26 INFO blockmanagement.BlockManager: minReplication             = 1
14/09/07 06:58:26 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
14/09/07 06:58:26 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
14/09/07 06:58:26 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
14/09/07 06:58:26 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
14/09/07 06:58:26 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
14/09/07 06:58:26 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
14/09/07 06:58:26 INFO namenode.FSNamesystem: supergroup          = supergroup
14/09/07 06:58:26 INFO namenode.FSNamesystem: isPermissionEnabled = true
14/09/07 06:58:26 INFO namenode.FSNamesystem: HA Enabled: false
14/09/07 06:58:26 INFO namenode.FSNamesystem: Append Enabled: true
14/09/07 06:58:26 INFO util.GSet: Computing capacity for map INodeMap
14/09/07 06:58:26 INFO util.GSet: VM type       = 64-bit
14/09/07 06:58:26 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB
14/09/07 06:58:26 INFO util.GSet: capacity      = 2^20 = 1048576 entries
14/09/07 06:58:26 INFO namenode.NameNode: Caching file names occuring more than 10 times
14/09/07 06:58:26 INFO util.GSet: Computing capacity for map cachedBlocks
14/09/07 06:58:26 INFO util.GSet: VM type       = 64-bit
14/09/07 06:58:26 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB
14/09/07 06:58:26 INFO util.GSet: capacity      = 2^18 = 262144 entries
14/09/07 06:58:26 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
14/09/07 06:58:26 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
14/09/07 06:58:26 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
14/09/07 06:58:26 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
14/09/07 06:58:26 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
14/09/07 06:58:26 INFO util.GSet: Computing capacity for map NameNodeRetryCache
14/09/07 06:58:26 INFO util.GSet: VM type       = 64-bit
14/09/07 06:58:26 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
14/09/07 06:58:26 INFO util.GSet: capacity      = 2^15 = 32768 entries
14/09/07 06:58:27 INFO namenode.AclConfigFlag: ACLs enabled? false
14/09/07 06:58:27 INFO namenode.FSImage: Allocated new BlockPoolId: BP-477312051-127.0.1.1-1410087507021
14/09/07 06:58:27 INFO common.Storage: Storage directory /home/sandeep/tools/hadoop/data/hdfs/namenode has been successfully formatted.
14/09/07 06:58:27 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
14/09/07 06:58:27 INFO util.ExitUtil: Exiting with status 0
14/09/07 06:58:27 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at sandeep-Latitude-6430U/127.0.1.1
************************************************************/
###############
# Start HDFS processes
###############
starting namenode, logging to /home/sandeep/tools/hadoop/2.4.1/logs/hadoop-sandeep-namenode-sandeep-Latitude-6430U.out
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
10118 DavGateway
26723 RemoteMavenServer
4403 Jps
26643 Main
11126 DavGateway
4336 NameNode
starting datanode, logging to /home/sandeep/tools/hadoop/2.4.1/logs/hadoop-sandeep-datanode-sandeep-Latitude-6430U.out
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
4438 DataNode
10118 DavGateway
26723 RemoteMavenServer
26643 Main
11126 DavGateway
4514 Jps
4336 NameNode
starting resourcemanager, logging to /home/sandeep/tools/hadoop/2.4.1/logs/yarn-sandeep-resourcemanager-sandeep-Latitude-6430U.out
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
4438 DataNode
10118 DavGateway
26723 RemoteMavenServer
4591 Jps
26643 Main
4554 ResourceManager
11126 DavGateway
4336 NameNode
starting nodemanager, logging to /home/sandeep/tools/hadoop/2.4.1/logs/yarn-sandeep-nodemanager-sandeep-Latitude-6430U.out
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
4438 DataNode
10118 DavGateway
26723 RemoteMavenServer
26643 Main
4554 ResourceManager
11126 DavGateway
4851 Jps
4632 NodeManager
4336 NameNode
starting historyserver, logging to /home/sandeep/tools/hadoop/2.4.1/logs/mapred-sandeep-historyserver-sandeep-Latitude-6430U.out
4438 DataNode
4901 JobHistoryServer
10118 DavGateway
26723 RemoteMavenServer
26643 Main
4554 ResourceManager
11126 DavGateway
5029 Jps
4632 NodeManager
4336 NameNode
###############
# Web interface
###############
##############
# Map Reduce
##############
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/09/07 06:58:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/09/07 06:58:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/09/07 06:58:44 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/09/07 06:58:44 INFO input.FileInputFormat: Total input paths to process : 1
14/09/07 06:58:44 INFO mapreduce.JobSubmitter: number of splits:1
14/09/07 06:58:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1410087517459_0001
14/09/07 06:58:45 INFO impl.YarnClientImpl: Submitted application application_1410087517459_0001
14/09/07 06:58:45 INFO mapreduce.Job: The url to track the job: http://sandeep-Latitude-6430U:8088/proxy/application_1410087517459_0001/
14/09/07 06:58:45 INFO mapreduce.Job: Running job: job_1410087517459_0001
14/09/07 06:58:51 INFO mapreduce.Job: Job job_1410087517459_0001 running in uber mode : false
14/09/07 06:58:51 INFO mapreduce.Job:  map 0% reduce 0%
14/09/07 06:58:56 INFO mapreduce.Job:  map 100% reduce 0%
14/09/07 06:59:01 INFO mapreduce.Job:  map 100% reduce 100%
14/09/07 06:59:01 INFO mapreduce.Job: Job job_1410087517459_0001 completed successfully
14/09/07 06:59:01 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=61
		FILE: Number of bytes written=186345
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=135
		HDFS: Number of bytes written=35
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2539
		Total time spent by all reduces in occupied slots (ms)=2775
		Total time spent by all map tasks (ms)=2539
		Total time spent by all reduce tasks (ms)=2775
		Total vcore-seconds taken by all map tasks=2539
		Total vcore-seconds taken by all reduce tasks=2775
		Total megabyte-seconds taken by all map tasks=2599936
		Total megabyte-seconds taken by all reduce tasks=2841600
	Map-Reduce Framework
		Map input records=2
		Map output records=8
		Map output bytes=70
		Map output materialized bytes=61
		Input split bytes=97
		Combine input records=8
		Combine output records=5
		Reduce input groups=5
		Reduce shuffle bytes=61
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		CPU time spent (ms)=1340
		Physical memory (bytes) snapshot=431792128
		Virtual memory (bytes) snapshot=1690664960
		Total committed heap usage (bytes)=354942976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=38
	File Output Format Counters 
		Bytes Written=35
Word Count Output
-----------------
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/09/07 06:59:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
This	2
another	1
is	2
line	2
one	1
#######
# HIVE
#######

Logging initialized using configuration in jar:file:/home/sandeep/tools/hive/0.13.1/lib/hive-common-0.13.1.jar!/hive-log4j.properties
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
drop table if exists page_view
OK
Time taken: 0.475 seconds

drop table if exists strange_string
OK
Time taken: 0.009 seconds

drop table if exists india_pow_gen
OK
Time taken: 0.009 seconds

drop table if exists edges
OK
Time taken: 0.009 seconds
[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building tingri_hive 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.4.1:clean (default-clean) @ tingri_hive ---
[INFO] Deleting /home/sandeep/projects/big_data/udf/target
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building tingri_hive 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ tingri_hive >>>
[WARNING] The artifact org.apache.commons:commons-io:jar:1.3.2 has been relocated to commons-io:commons-io:jar:1.3.2
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ tingri_hive ---
[debug] execute contextualize
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/sandeep/projects/big_data/udf/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ tingri_hive ---
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 1 source file to /home/sandeep/projects/big_data/udf/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ tingri_hive ---
[debug] execute contextualize
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/sandeep/projects/big_data/udf/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:testCompile (default-testCompile) @ tingri_hive ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.8:test (default-test) @ tingri_hive ---
[INFO] No tests to run.
[INFO] Surefire report directory: /home/sandeep/projects/big_data/udf/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
There are no tests to run.

Results :

Tests run: 0, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:2.3.2:jar (default-jar) @ tingri_hive ---
[INFO] Building jar: /home/sandeep/projects/big_data/udf/target/tingri_hive-0.1.jar
[INFO] 
[INFO] <<< maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ tingri_hive <<<
[INFO] 
[INFO] --- maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ tingri_hive ---
[INFO] Building jar: /home/sandeep/projects/big_data/udf/target/tingri_hive-0.1-jar-with-dependencies.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3.693s
[INFO] Finished at: Sun Sep 07 06:59:14 EDT 2014
[INFO] Final Memory: 27M/214M
[INFO] ------------------------------------------------------------------------
[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building connected_components 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.4.1:clean (default-clean) @ connected_components ---
[INFO] Deleting /home/sandeep/projects/big_data/udaf/target
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building connected_components 0.1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] >>> maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ connected_components >>>
[WARNING] The artifact org.apache.commons:commons-io:jar:1.3.2 has been relocated to commons-io:commons-io:jar:1.3.2
[INFO] 
[INFO] --- maven-resources-plugin:2.5:resources (default-resources) @ connected_components ---
[debug] execute contextualize
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] Copying 0 resource
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ connected_components ---
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 1 source file to /home/sandeep/projects/big_data/udaf/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.5:testResources (default-testResources) @ connected_components ---
[debug] execute contextualize
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/sandeep/projects/big_data/udaf/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:2.3.2:testCompile (default-testCompile) @ connected_components ---
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 1 source file to /home/sandeep/projects/big_data/udaf/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.8:test (default-test) @ connected_components ---
[INFO] Surefire report directory: /home/sandeep/projects/big_data/udaf/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running me.tingri.hive.udaf.ConnectedComponentsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.063 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:2.3.2:jar (default-jar) @ connected_components ---
[INFO] Building jar: /home/sandeep/projects/big_data/udaf/target/connected_components-0.1.jar
[INFO] 
[INFO] <<< maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ connected_components <<<
[INFO] 
[INFO] --- maven-assembly-plugin:2.2-beta-5:assembly (default-cli) @ connected_components ---
[INFO] Building jar: /home/sandeep/projects/big_data/udaf/target/connected_components-0.1-jar-with-dependencies.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 4.511s
[INFO] Finished at: Sun Sep 07 06:59:20 EDT 2014
[INFO] Final Memory: 36M/292M
[INFO] ------------------------------------------------------------------------

Logging initialized using configuration in jar:file:/home/sandeep/tools/hive/0.13.1/lib/hive-common-0.13.1.jar!/hive-log4j.properties
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
DROP FUNCTION IF EXISTS components
OK
Time taken: 0.797 seconds
ADD JAR ${env:PROJECT_HOME}/udaf/target/connected_components-0.1-jar-with-dependencies.jar
Added /home/sandeep/projects/big_data/udaf/target/connected_components-0.1-jar-with-dependencies.jar to class path
Added resource: /home/sandeep/projects/big_data/udaf/target/connected_components-0.1-jar-with-dependencies.jar


create temporary function components as 'me.tingri.hive.udaf.ConnectedComponents'
OK
Time taken: 0.017 seconds


CREATE TABLE edges(node1 STRING, node2 STRING)
  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
OK
Time taken: 0.453 seconds


LOAD DATA LOCAL INPATH '${env:PROJECT_HOME}/edges.csv' OVERWRITE INTO TABLE edges
Copying data from file:/home/sandeep/projects/big_data/edges.csv
Copying file: file:/home/sandeep/projects/big_data/edges.csv
Loading data to table default.edges
rmr: DEPRECATED: Please use 'rm -r' instead.
Deleted hdfs://localhost:9000/user/hive/warehouse/edges
Table default.edges stats: [numFiles=1, numRows=0, totalSize=50, rawDataSize=0]
OK
Time taken: 0.72 seconds


SELECT components(node1, node2) from edges
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1410087517459_0002, Tracking URL = http://sandeep-Latitude-6430U:8088/proxy/application_1410087517459_0002/
Kill Command = /home/sandeep/tools/hadoop/2.4.1/bin/hadoop job  -kill job_1410087517459_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2014-09-07 06:59:35,121 Stage-1 map = 0%,  reduce = 0%
2014-09-07 06:59:39,419 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 0.96 sec
2014-09-07 06:59:45,636 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.3 sec
MapReduce Total cumulative CPU time: 2 seconds 300 msec
Ended Job = job_1410087517459_0002
MapReduce Jobs Launched: 
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 2.3 sec   HDFS Read: 261 HDFS Write: 52 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 300 msec
OK
{"N9":["N9","N4","N20"],"N7":["N7","N8"],"N1":["N1","N3","N5","N2","N6"],"N10":["N10","N11"]}
Time taken: 18.54 seconds, Fetched: 1 row(s)

Logging initialized using configuration in jar:file:/home/sandeep/tools/hive/0.13.1/lib/hive-common-0.13.1.jar!/hive-log4j.properties
OpenJDK 64-Bit Server VM warning: You have loaded library /home/sandeep/tools/hadoop/2.4.1/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
drop table if exists page_view
OK
Time taken: 0.543 seconds

drop table if exists strange_string
OK
Time taken: 0.009 seconds

drop table if exists india_pow_gen
OK
Time taken: 0.01 seconds

drop table if exists edges
OK
Time taken: 1.287 seconds
########################
# Stop the processes
########################
stopping namenode
stopping datanode
stopping resourcemanager
stopping nodemanager
nodemanager did not stop gracefully after 5 seconds: killing with kill -9
stopping historyserver
